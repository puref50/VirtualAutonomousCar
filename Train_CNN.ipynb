{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a024e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f193d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up image size\n",
    "\n",
    "WIDTH, HEIGHT = 320, 240\n",
    "HEIGHT_REQUIRED_PORTION = 0.5\n",
    "WIDTH_REQUIRED_PORTION = 0.9\n",
    "\n",
    "height_from = int(HEIGHT * (1 - HEIGHT_REQUIRED_PORTION))\n",
    "width_from = int((WIDTH - WIDTH * WIDTH_REQUIRED_PORTION) / 2)\n",
    "width_to = width_from + int(WIDTH_REQUIRED_PORTION * WIDTH)\n",
    "\n",
    "new_height = HEIGHT - height_from\n",
    "new_width = width_to - width_from\n",
    "image_size = (new_width, new_height)\n",
    "\n",
    "MAX_STEER_DEGREES = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba534ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "    image = image[height_from:, width_from:width_to]\n",
    "    return image / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4754d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom data generator\n",
    "\n",
    "def custom_data_generator(image_files, batch_size=64):\n",
    "    while True:\n",
    "        batch = random.sample(image_files, batch_size)\n",
    "        batch_images, batch_input_2, batch_labels = [], [], []\n",
    "        for path in batch:\n",
    "            parts = os.path.basename(path).split('_')\n",
    "            steer = float(parts[2].replace('.png', ''))\n",
    "            steer = np.clip(steer, -MAX_STEER_DEGREES, MAX_STEER_DEGREES) / MAX_STEER_DEGREES\n",
    "            input_2 = int(parts[1])\n",
    "            image = preprocess_image(path)\n",
    "            batch_images.append(image)\n",
    "            batch_input_2.append(input_2)\n",
    "            batch_labels.append(steer)\n",
    "        yield [np.array(batch_images), np.array(batch_input_2)], np.array(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e39b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN model to extract features\n",
    "\n",
    "def create_feature_extractor():\n",
    "    image_input = Input(shape=(new_height, new_width, 3))\n",
    "    int_input = Input(shape=(1,))\n",
    "\n",
    "    x = Conv2D(64, (6, 6), activation='relu', padding='same')(image_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (6, 6), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (6, 6), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (6, 6), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Dense(8, activation='relu', name='feature_dense')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(4, activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    features = Concatenate()([x, int_input])\n",
    "    output = Dense(1)(features)  # steer 值输出，用于训练\n",
    "\n",
    "    model = Model(inputs=[image_input, int_input], outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21027f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of image file paths and labels\n",
    "\n",
    "data_dir = 'D:\\FP\\Carla\\CNN/_img'\n",
    "image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.png')]\n",
    "random.shuffle(image_files)\n",
    "split = int(0.8 * len(image_files))\n",
    "train_files, val_files = image_files[:split], image_files[split:]\n",
    "\n",
    "train_gen = custom_data_generator(train_files, batch_size=64)\n",
    "val_gen = custom_data_generator(val_files, batch_size=64)\n",
    "\n",
    "model = create_feature_extractor()\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(train_files)//64,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(val_files)//64,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dense layer output\n",
    "\n",
    "feature_output = model.get_layer('feature_dense').output\n",
    "feature_model = Model(inputs=model.input, outputs=feature_output)\n",
    "feature_model.save(\"model_saved_from_CNN.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
